"use client"

import type React from "react"
import { useState, useRef, useEffect } from "react"
import { Send, Mic, MicOff, Volume2 } from "lucide-react"

interface Message {
  id: string
  type: "user" | "assistant"
  content: string
  timestamp: Date
}

interface ChatInterfaceProps {
  selectedPersona: string
  initialMessages: Message[]
  onMessagesUpdate: (messages: Message[]) => void
}

export default function ChatInterface({
  selectedPersona,
  initialMessages,
  onMessagesUpdate,
}: ChatInterfaceProps) {
  const [messages, setMessages] = useState<Message[]>(initialMessages)
  const [inputValue, setInputValue] = useState("")
  const [isLoading, setIsLoading] = useState(false)
  const [chatMode, setChatMode] = useState<"text-to-text" | "speech-to-speech" | "text-to-speech">("text-to-text")
  const [isRecording, setIsRecording] = useState(false)
  const scrollAreaRef = useRef<HTMLDivElement>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])

  useEffect(() => {
    if (scrollAreaRef.current) {
      scrollAreaRef.current.scrollTop = scrollAreaRef.current.scrollHeight
    }
  }, [messages])

  useEffect(() => {
    // messages ìƒíƒœê°€ ë³€ê²½ë  ë•Œë§ˆë‹¤ ë¶€ëª¨ì—ê²Œ ì•Œë¦¼
    onMessagesUpdate(messages)
  }, [messages, onMessagesUpdate])

  const addMessage = (type: "user" | "assistant", content: string) => {
    const newMessage: Message = {
      id: Date.now().toString(),
      type,
      content,
      timestamp: new Date(),
    }
    setMessages((prev) => [...prev, newMessage])
  }

  const handleTextSubmit = async (text: string) => {
    if (!text.trim() || !selectedPersona) return

    addMessage("user", text)
    setIsLoading(true)

    try {
      const response = await fetch(`${process.env.NEXT_PUBLIC_BACKEND_URL}/api/chat`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          message: text,
          mode: chatMode,
          persona: selectedPersona,
        }),
      })

      const data = await response.json()

      if (data.success) {
        addMessage("assistant", data.response)

        // TTS ëª¨ë“œì¸ ê²½ìš° ìŒì„± ì¬ìƒ
        if (chatMode === "text-to-speech" && data.audio_url) {
          const audio = new Audio(`${process.env.NEXT_PUBLIC_BACKEND_URL}${data.audio_url}`)
          audio.play()
        }
      } else {
        addMessage("assistant", "ì£„ì†¡í•´ìš”, ì‘ë‹µì„ ìƒì„±í•˜ëŠ”ë° ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.")
      }
    } catch (error) {
      console.error("Chat error:", error)
      addMessage("assistant", "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    } finally {
      setIsLoading(false)
    }
  }

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault()
    handleTextSubmit(inputValue)
    setInputValue("")
  }

  const handleVoiceRecord = async () => {
    if (isRecording) {
      // ë…¹ìŒ ì¤‘ì§€
      setIsRecording(false)
      
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
        mediaRecorderRef.current.stop()
      }
    } else {
      // ë…¹ìŒ ì‹œì‘
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            sampleRate: 16000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true
          } 
        })
        
        audioChunksRef.current = []
        
        const mediaRecorder = new MediaRecorder(stream, {
          mimeType: 'audio/webm;codecs=opus'
        })
        
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunksRef.current.push(event.data)
          }
        }
        
        mediaRecorder.onstop = async () => {
          // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
          stream.getTracks().forEach(track => track.stop())
          
          if (audioChunksRef.current.length > 0) {
            const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
            await uploadAudioForTranscription(audioBlob)
          }
        }
        
        mediaRecorderRef.current = mediaRecorder
        mediaRecorder.start(1000) // 1ì´ˆë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘
        setIsRecording(true)
        
      } catch (error) {
        console.error("ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤:", error)
        alert("ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.")
      }
    }
  }

  const uploadAudioForTranscription = async (audioBlob: Blob) => {
    try {
      setIsLoading(true)
      console.log('ğŸ¤ ìŒì„± íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘:', audioBlob.size, 'bytes')
      
      const formData = new FormData()
      formData.append('file', audioBlob, 'recording.webm')
      
      const backendUrl = process.env.NEXT_PUBLIC_BACKEND_URL || 'http://localhost:8000'
      console.log('ğŸ“¡ Backend URL:', `${backendUrl}/api/speech/upload`)
      
      const response = await fetch(`${backendUrl}/api/speech/upload`, {
        method: 'POST',
        body: formData,
      })
      
      const data = await response.json()
      console.log('ğŸ“ STT ê²°ê³¼:', data)
      
      if (data.success && data.transcription) {
        // ìŒì„± ì¸ì‹ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œí•˜ê³  AI ì‘ë‹µ ìš”ì²­
        console.log('âœ… ìŒì„± ì¸ì‹ ì„±ê³µ:', data.transcription)
        addMessage("user", `ğŸ¤ ${data.transcription}`)
        
        // AI ì‘ë‹µ ìš”ì²­
        const chatResponse = await fetch(`${process.env.NEXT_PUBLIC_BACKEND_URL}/api/chat`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            message: data.transcription,
            mode: chatMode,
            persona: selectedPersona,
          }),
        })

        const chatData = await chatResponse.json()

        if (chatData.success) {
          addMessage("assistant", chatData.response)

          // ìŒì„± ëª¨ë“œì¸ ê²½ìš° TTS ì¬ìƒ
          if (chatMode === "speech-to-speech" && chatData.audio_url) {
            const audio = new Audio(`${process.env.NEXT_PUBLIC_BACKEND_URL}${chatData.audio_url}`)
            audio.play()
          }
        } else {
          addMessage("assistant", "ì£„ì†¡í•´ìš”, ì‘ë‹µì„ ìƒì„±í•˜ëŠ”ë° ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.")
        }
      } else {
        console.error("ìŒì„± ì¸ì‹ ì‹¤íŒ¨:", data)
        addMessage("assistant", "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
      }
    } catch (error) {
      console.error("ìŒì„± ì—…ë¡œë“œ ì˜¤ë¥˜:", error)
      addMessage("assistant", "ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    } finally {
      setIsLoading(false)
    }
  }

  const playLastResponse = () => {
    const lastAssistantMessage = messages.filter((m) => m.type === "assistant").pop()
    if (lastAssistantMessage) {
      fetch(`${process.env.NEXT_PUBLIC_BACKEND_URL}/api/speech/tts`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text: lastAssistantMessage.content }),
      })
        .then((response) => response.json())
        .then((data) => {
          if (data.success && data.audio_url) {
            const audio = new Audio(`${process.env.NEXT_PUBLIC_BACKEND_URL}${data.audio_url}`)
            audio.play()
          }
        })
        .catch((error) => console.error("TTS error:", error))
    }
  }

  return (
    <div className="flex flex-col h-screen pt-20 pb-4 pr-6 pl-6">
      {/* í—¤ë” ë†’ì´ë§Œí¼ íŒ¨ë”© ì¶”ê°€ (pt-20 = 80px) */}
      
      {/* ëª¨ë“œ ì„ íƒ */}
      <div className="mb-4 bg-white p-4 rounded-lg shadow-sm border border-gray-200">
        <label className="block text-sm font-medium text-gray-700 mb-2">
          ëŒ€í™” ëª¨ë“œ ì„ íƒ
        </label>
        <select 
          value={chatMode} 
          onChange={(e) => setChatMode(e.target.value as any)}
          className="w-64 px-3 py-2 border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-purple-500 bg-white"
        >
          <option value="text-to-text">ğŸ“ í…ìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸</option>
          <option value="speech-to-speech">ğŸ¤ ìŒì„± â†’ ìŒì„±</option>
          <option value="text-to-speech">ğŸ“ í…ìŠ¤íŠ¸ â†’ ğŸ”Š ìŒì„±</option>
        </select>
        <p className="text-sm text-gray-600 mt-2">
          {chatMode === "text-to-text" && "í…ìŠ¤íŠ¸ë¡œ ì…ë ¥í•˜ê³  í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µë°›ê¸°"}
          {chatMode === "speech-to-speech" && "ìŒì„±ìœ¼ë¡œ ì…ë ¥í•˜ê³  ìŒì„±ìœ¼ë¡œ ì‘ë‹µë°›ê¸°"}
          {chatMode === "text-to-speech" && "í…ìŠ¤íŠ¸ë¡œ ì…ë ¥í•˜ê³  ìŒì„±ìœ¼ë¡œ ì‘ë‹µë°›ê¸°"}
        </p>
      </div>

      {/* ì±„íŒ… ì˜ì—­ */}
      <div className="flex-1 flex flex-col bg-white border border-gray-200 rounded-lg shadow-sm min-h-0">
        <div className="flex-1 p-4 overflow-y-auto" ref={scrollAreaRef}>
          <div className="space-y-4">
            {messages.length === 0 && (
              <div className="text-center text-gray-500 py-12">
                <div className="text-6xl mb-4">
                  {chatMode === "text-to-text" ? "ğŸ“" : 
                   chatMode === "speech-to-speech" ? "ğŸ¤" : "ğŸ”Š"}
                </div>
                <p className="text-lg font-medium mb-2">
                  {selectedPersona ? `${selectedPersona}ì™€ ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”!` : "í˜ë¥´ì†Œë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”"}
                </p>
                <p className="text-sm text-gray-400">
                  {chatMode === "speech-to-speech" ? "ìŒì„± ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”" : "ì•„ë˜ì— ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"}
                </p>
              </div>
            )}

            {messages.map((message) => (
              <div key={message.id} className={`flex ${message.type === "user" ? "justify-end" : "justify-start"}`}>
                <div
                  className={`max-w-[70%] rounded-lg px-4 py-3 shadow-sm ${
                    message.type === "user" 
                      ? "bg-purple-600 text-white" 
                      : "bg-gray-100 text-gray-900 border border-gray-200"
                  }`}
                >
                  <p className="whitespace-pre-wrap leading-relaxed">{message.content}</p>
                  <p className="text-xs opacity-70 mt-2">{message.timestamp.toLocaleTimeString()}</p>
                </div>
              </div>
            ))}

            {isLoading && (
              <div className="flex justify-start">
                <div className="bg-gray-100 rounded-lg px-4 py-3 border border-gray-200">
                  <div className="flex space-x-1">
                    <div className="w-2 h-2 bg-purple-400 rounded-full animate-bounce"></div>
                    <div
                      className="w-2 h-2 bg-purple-400 rounded-full animate-bounce"
                      style={{ animationDelay: "0.1s" }}
                    ></div>
                    <div
                      className="w-2 h-2 bg-purple-400 rounded-full animate-bounce"
                      style={{ animationDelay: "0.2s" }}
                    ></div>
                  </div>
                </div>
              </div>
            )}
          </div>
        </div>

        {/* ì…ë ¥ ì˜ì—­ */}
        <div className="border-t bg-gray-50 p-4 rounded-b-lg">
          <form onSubmit={handleSubmit} className="flex space-x-3">
            <div className="flex-1 relative">
              <input
                type="text"
                value={inputValue}
                onChange={(e) => setInputValue(e.target.value)}
                placeholder={
                  chatMode === "speech-to-speech"
                    ? "ìŒì„± ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”..."
                    : `${selectedPersona || 'í˜ë¥´ì†Œë‚˜'}ì—ê²Œ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...`
                }
                disabled={isLoading || chatMode === "speech-to-speech"}
                className="w-full px-4 py-3 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-purple-500 focus:border-transparent bg-white disabled:bg-gray-100 disabled:text-gray-500"
              />
              {isRecording && (
                <div className="absolute right-3 top-1/2 transform -translate-y-1/2">
                  <div className="flex items-center space-x-2 text-red-600">
                    <div className="w-2 h-2 bg-red-500 rounded-full animate-pulse"></div>
                    <span className="text-sm font-medium">ë…¹ìŒì¤‘</span>
                  </div>
                </div>
              )}
            </div>

            {chatMode === "speech-to-speech" ? (
              <button
                type="button"
                onClick={handleVoiceRecord}
                disabled={isLoading}
                className={`px-6 py-3 rounded-lg font-medium transition-all duration-200 flex items-center space-x-2 ${
                  isRecording 
                    ? "bg-red-600 text-white hover:bg-red-700 animate-pulse shadow-lg" 
                    : "bg-purple-600 text-white hover:bg-purple-700 shadow-md hover:shadow-lg"
                } disabled:opacity-50 disabled:cursor-not-allowed`}
                title={isRecording ? "ë…¹ìŒ ì¤‘ì§€ ë° ì „ì†¡" : "ìŒì„± ë…¹ìŒ ì‹œì‘"}
              >
                {isRecording ? (
                  <>
                    <MicOff className="h-5 w-5" />
                    <span className="text-sm">ì¤‘ì§€</span>
                  </>
                ) : (
                  <>
                    <Mic className="h-5 w-5" />
                    <span className="text-sm">ë…¹ìŒ</span>
                  </>
                )}
              </button>
            ) : (
              <button 
                type="submit" 
                disabled={isLoading || !inputValue.trim()}
                className="px-6 py-3 bg-purple-600 text-white rounded-lg hover:bg-purple-700 disabled:opacity-50 disabled:cursor-not-allowed font-medium transition-all duration-200 shadow-md hover:shadow-lg"
              >
                {isLoading ? (
                  <div className="w-5 h-5 border-2 border-white border-t-transparent rounded-full animate-spin"></div>
                ) : (
                  <Send className="h-5 w-5" />
                )}
              </button>
            )}

            {(chatMode === "text-to-speech" || chatMode === "speech-to-speech") && (
              <button
                type="button"
                onClick={playLastResponse}
                disabled={messages.filter((m) => m.type === "assistant").length === 0}
                className="px-4 py-3 border border-gray-300 text-gray-600 rounded-lg hover:bg-gray-50 disabled:opacity-50 disabled:cursor-not-allowed transition-all duration-200 bg-white shadow-sm hover:shadow-md"
                title="ë§ˆì§€ë§‰ ì‘ë‹µ ë‹¤ì‹œ ë“£ê¸°"
              >
                <Volume2 className="h-5 w-5" />
              </button>
            )}
          </form>
          
          {/* ë„ì›€ë§ í…ìŠ¤íŠ¸ */}
          <div className="mt-3 text-center">
            <p className="text-xs text-gray-500">
              {chatMode === "speech-to-speech" && "ğŸ¤ ìŒì„± ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•˜ê³ , ë‹¤ì‹œ ëˆŒëŸ¬ì„œ ì „ì†¡í•˜ì„¸ìš”"}
              {chatMode === "text-to-speech" && "ğŸ“ ì…ë ¥í•œ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë“¤ì„ ìˆ˜ ìˆì–´ìš”"}
              {chatMode === "text-to-text" && "ğŸ’¬ Enter í‚¤ë¥¼ ëˆŒëŸ¬ì„œ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ì„¸ìš”"}
            </p>
          </div>
        </div>
      </div>
    </div>
  )
}