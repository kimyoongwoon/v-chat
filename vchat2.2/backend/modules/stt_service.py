"""
STT (Speech-to-Text) ì„œë¹„ìŠ¤ ëª¨ë“ˆ
OpenAI Whisper APIë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹
"""

import os
import pyaudio
import wave
import threading
import time
import tempfile
import tiktoken
import numpy as np
from openai import OpenAI
from .audio_utils import validate_api_keys

class RealTimeSTT:
    """ì‹¤ì‹œê°„ STT ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, silence_threshold=2.0, sample_rate=44100, chunk_size=1024):
        """
        STT ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            silence_threshold (float): ì¹¨ë¬µ ê°ì§€ ì„ê³„ê°’ (ì´ˆ)
            sample_rate (int): ìƒ˜í”Œë§ ë ˆì´íŠ¸
            chunk_size (int): ì˜¤ë””ì˜¤ ì²­í¬ í¬ê¸°
        """
        # API í‚¤ ê²€ì¦
        validate_api_keys()
        
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.silence_threshold = silence_threshold
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        self.format = pyaudio.paInt16
        self.channels = 1
        
        # ë…¹ìŒ ìƒíƒœ ê´€ë¦¬
        self.is_recording = False
        self.is_speaking = False
        self.audio_frames = []
        self.last_sound_time = 0
        self.volume_threshold = 500
        
        # PyAudio ì´ˆê¸°í™”
        self.audio = pyaudio.PyAudio()
        
        # tiktoken ì¸ì½”ë” (í† í° ê³„ì‚°ìš©)
        try:
            self.encoding = tiktoken.get_encoding("cl100k_base")
        except:
            self.encoding = None
    
    def is_silence(self, audio_chunk):
        """ì˜¤ë””ì˜¤ ì²­í¬ê°€ ì¹¨ë¬µì¸ì§€ í™•ì¸"""
        audio_data = np.frombuffer(audio_chunk, dtype=np.int16)
        volume = np.sqrt(np.mean(audio_data**2))
        return volume < self.volume_threshold
    
    def save_audio_to_temp_file(self, audio_frames):
        """ì˜¤ë””ì˜¤ í”„ë ˆì„ì„ ì„ì‹œ WAV íŒŒì¼ë¡œ ì €ì¥"""
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
            temp_filename = temp_file.name
        
        with wave.open(temp_filename, 'wb') as wf:
            wf.setnchannels(self.channels)
            wf.setsampwidth(self.audio.get_sample_size(self.format))
            wf.setframerate(self.sample_rate)
            wf.writeframes(b''.join(audio_frames))
        
        return temp_filename
    
    def transcribe_audio_file(self, audio_file_path, language="ko"):
        """ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            with open(audio_file_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language=language,
                    response_format="json"
                )
            return transcript.text
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg and "quota" in error_msg:
                return "âŒ OpenAI API í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
            elif "401" in error_msg:
                return "âŒ API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            else:
                return f"âŒ ë³€í™˜ ì˜¤ë¥˜: {error_msg}"
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            try:
                os.unlink(audio_file_path)
            except:
                pass
    
    def audio_callback(self, in_data, frame_count, time_info, status):
        """ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì½œë°± í•¨ìˆ˜"""
        if not self.is_recording:
            return (in_data, pyaudio.paContinue)

        current_time = time.time()
        
        if not self.is_silence(in_data):
            self.is_speaking = True
            self.last_sound_time = current_time
            self.audio_frames.append(in_data)
            print("ğŸ¤ ë…¹ìŒ ì¤‘...", end="\r")
        else:
            if self.is_speaking and (current_time - self.last_sound_time) > self.silence_threshold:
                print("\nâ¸ï¸  ì¹¨ë¬µ ê°ì§€: ë…¹ìŒì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                self.is_recording = False
            elif self.is_speaking:
                self.audio_frames.append(in_data)
        
        return (in_data, pyaudio.paContinue)
    
    def record_and_transcribe(self):
        """
        ë…¹ìŒí•˜ê³  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ë©”ì¸ì—ì„œ í˜¸ì¶œí•  í•¨ìˆ˜)
        
        Returns:
            str: ë³€í™˜ëœ í…ìŠ¤íŠ¸ ë˜ëŠ” None
        """
        if self.is_recording:
            return None
        
        self.is_recording = True
        self.is_speaking = False
        self.audio_frames = []
        self.last_sound_time = time.time()
        
        # ìŠ¤íŠ¸ë¦¼ ì‹œì‘
        stream = self.audio.open(
            format=self.format,
            channels=self.channels,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size,
            stream_callback=self.audio_callback
        )
        
        # Enter í‚¤ ê°ì§€ ìŠ¤ë ˆë“œ
        stop_event = threading.Event()
        
        def wait_for_enter():
            try:
                input()  # Enter ëŒ€ê¸°
                if self.is_recording:
                    print("\nğŸ”” Enter ê°ì§€: ë…¹ìŒì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    self.is_recording = False
                stop_event.set()
            except:
                stop_event.set()
        
        enter_thread = threading.Thread(target=wait_for_enter, daemon=True)
        enter_thread.start()
        
        stream.start_stream()
        
        # ë…¹ìŒ ëŒ€ê¸°
        while stream.is_active() and self.is_recording:
            time.sleep(0.1)
        
        # ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        try:
            stream.stop_stream()
            stream.close()
        except:
            pass
        
        # STT ì²˜ë¦¬
        if len(self.audio_frames) > 0:
            print("ğŸ”„ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")
            temp_file = self.save_audio_to_temp_file(self.audio_frames)
            result = self.transcribe_audio_file(temp_file)
            
            # í† í° ì •ë³´ ì¶œë ¥
            if self.encoding and result and not result.startswith("âŒ"):
                try:
                    tokens = self.encoding.encode(result)
                    token_count = len(tokens)
                    print(f"ğŸ”¢ í† í° ê°œìˆ˜: {token_count}ê°œ")
                except:
                    pass
            
            return result
        else:
            print("âŒ ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
    
    def terminate(self):
        """ìì› í•´ì œ"""
        self.is_recording = False
        try:
            self.audio.terminate()
        except:
            pass
